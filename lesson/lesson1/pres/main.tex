\documentclass{beamer}
% Графика ----------------------------
\usepackage{graphicx} 
% Математика -------------------------
\usepackage{cmap} 
\usepackage{amsmath}
% Русский язык -----------------------
\usepackage[utf8]{inputenc} 
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}

% Для включение определенной лекции
\includeonlylecture{lec1}

% Размер сторон:
% ширина – 128 мм, высота – 96 мм (соотношение сторон 4:3).
\title{Искусственные нейронные сети}
\author[Даниил Копылов]{Копылов Д.Е., Михайлов А.А.}
% \date{}
\institute[ИДСТУ СО РАН, ИСП РАН, ИМИТ ИГУ]{
\inst{1}Институт динамики систем и теории управления им. В.М. Матросова Сибирского отделения Российской академии наук \and
\inst{2}Институт системного программирования им. В.П. Иванникова \\Российской академии наук \and
\inst{3}Институт математики и информационных технологий \\Иркутский государственный университет
}

%\insertauthor, \insertdate, \insertinstitute, \inserttitle, \insertsubtitle и \inserttitlegraphic

\begin{document}
\begin{frame}
    \maketitle
\end{frame}

%\lecture[Задача классификации]{Задача классификации}{lec2}
\begin{frame}{Лекция 2}
%\insertlecture
% \insertshortlecture %короткое название лекции
\end{frame}

\begin{frame}{формальная постановка задачи}
    Пусть есть два множества $X$ - множества объектов, $Y$ - множество ответов и предполагается,
    что существует функциональная зависимость 
    \begin{equation}
        f:X \to Y.
    \end{equation}
    Зависимость не известна, известна только совокупность $S$ пар вида (объект, ответ)

    \begin{equation}
	    S = \{(x_i, y_{x_i} = f(x_i)) \in X \times Y | i = 1, ..., l\} 
    \end{equation}

    Требуется найти приближенный вид этой функции $f$ путем построения аппроксимирующей функции $f_S(x): X \to Y$, такую, что
    \begin{equation}
    	\forall x \in X \quad f_S(x) \approx f(x).
    \end{equation}
\end{frame}

\begin{frame}{Переход от объектов к векторам}
	\begin{block}{Множества признаков}
		$I$ - множество признаков (features),

		Каждому $i \in I$ сапоставляется некоторое множество $D_i$ (множество значений признака $i$) 
	\end{block}

	\begin{block}{Признаки объектов}
		У объекта зафиксируем конечное число признаков $n$ и пронумеруем их $1, 2, ..., n$.
		
		$x^i \in D_i$

		$x = (x^1, x^2, ..., x^n)^T \in D_1 \times D_2 \times ... \times D_n$
		
	\end{block}
\end{frame}
\begin{frame}{Виды задач по возвращаемым ответам}
	\begin{block}{Множество ответов}
		\begin{enumerate}
			\item $Y = \{0, 1\}$ - бинарная классификация (фильтер Байеса)
			\item $Y = \{c_1, c_2, ..., c_m\}$ - классификация 
			\item $Y = \{"a", "b", ..., "z"\}$ - задача распознавания символов
			\item $Y = \{1, 2, ..., N\}$ и $i \neq j, y_i \neq y_j$ - задача ранжирования
			\item $Y = \{1, 2, 3, ...N, ...\}$ - кластеризация
			\item $Y = R^m$ - задача регрессии 
		\end{enumerate}
	\end{block}
\end{frame}
\begin{frame}{Функция потерь}
	\begin{block}{Функция потерь (loss function)}
		Функция потерь - функция, которая сопоставляет паре $f_S, x$, где $x \in X$ число $Loss(f_S, x)$ и характеризует величину ошибки аппроксимации $f_S$ на объекте $x \in X$.
	\end{block}
	\begin{block}{Виды функций потерь}
                \begin{enumerate}
	                \item $Loss(f_S, x) = \begin{cases} 0,& if \quad f_S(x) = f(x); \\ 1,& else \end{cases}$
                       	\item $Loss(f_S, x) = |f_S(x) - f(x)|$ $Loss(f_S, x) = (f_S(x) - f(x))^2$
                \end{enumerate}
	\end{block}
\end{frame}
\begin{frame}{Функция потерь для выборки}
	\begin{block}{Функция потерь для обучающей выборки}
		Если $S' = \{(x_i', y_i'), i=1, 2, ... l'\}$ соответствует функции $f:X\to Y$, также как и $S$, то
		\begin{equation}
			Loss(f_S, S') = \frac{1}{l'}\sum_{i=1}^{l'} Loss(f_S, x_i')
		\end{equation}

		Для всего $S$ это функция эмпирического риска
		\begin{equation}
			Q(f_S) = Loss(f_S, S) 
		\end{equation}
	\end{block}
\end{frame}
\begin{frame}{Гиперплоскости}
	Гиперплоскость в пространстве $R^n$ называется множество точек $x \in R^n$ удовлетворяющих уравнению 
\begin{equation}
	\langle x, w \rangle = w_0.
\end{equation}
	Гиперплоскостью можно разделить множество $X$ на $X^+$ и $X^-$, так что $\forall x \in X^+ , \langle x, w \rangle - w_0 \geq 0$ и $\forall x \in X^-,  \langle x, w\rangle - w_0 \leq 0$. 
	\begin{block}{Подбор параметров $w$}
		Если функция $Y = \{-1, 1\}$ , то в качестве функции $f_S(x)$ можно выбрать следующую функцию
		\begin{equation}
                        f_S(x) = sign(\langle x, w\rangle - w_0)
		\end{equation}
		\begin{equation}
			(w, w_0) = \arg \min_{w, w_0} Q(f_S)
		\end{equation}
	\end{block}
\end{frame}
\begin{frame}
    % \url{http://intsys.msu.ru/staff/mironov/machine_learning_vol1.pdf}
    % \url{}
\end{frame}


\end{document}
